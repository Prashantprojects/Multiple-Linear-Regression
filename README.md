# Multiple-Linear-Regression

The purpose of this project was to get familiar with Multiple Linear Regression (MLR). 

**MLR.ipynb**: shows how MLR is used on a dataset


---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

# Linear Regression Machine Learning approach

A linear Regression is a **linear approximation** of a **relationship** between conditional expectations of two or more variables

##### 1. What Are the Basic Assumption?
There are four assumptions associated with a linear regression model:

1. Linearity: The relationship between X and the mean of Y is linear.
2. Homoscedasticity: The variance of residual is the same for any value of X.
3. Independence: Observations are independent of each other.
4. Normality: For any fixed value of X, Y is normally distributed.

#####  2. Advantages
1. Linear regression performs exceptionally well for linearly separable data
2. Easy to implement and train the model
3. It can handle overfitting using 

##### 3. Disadvantages
1. Sometimes Lot of Feature Engineering Is required
2. If the independent features are correlated it may affect performance
3. It is often quite prone to noise and overfitting

##### 4. Whether Feature Scaling is required?
Yes
##### 5. Impact of Missing Values?
It is sensitive to missing values
##### 6. Impact of outliers?
linear regression needs the relationship between the independent and dependent variables to be linear. It is also important to check for outliers since linear regression is sensitive to outlier effects.

##### Types of Problems it can solve(Supervised)
1. Regression
